{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f22038e5-cb9f-452e-ae98-9f7b3816a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff75f8f1-5a2d-4f13-8d8f-8b1eaca1bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plaintext:\n",
    "  \"\"\"Class with different computations for a plaintext object\n",
    "  \"\"\"\n",
    "  def __init__(self, pslots, pnum_slots):\n",
    "    \"\"\"\n",
    "    pslots: 1D array\n",
    "    \"\"\"\n",
    "    if len(pslots) <= pnum_slots:\n",
    "        concatenatedSlots = np.concatenate((pslots, np.zeros((pnum_slots - len(pslots)))))\n",
    "        self.slots = np.array(concatenatedSlots)\n",
    "        self.num_slots = pnum_slots\n",
    "    else : \n",
    "      raise Exception(\"num_slots is too small.\")\n",
    "\n",
    "  def __str__(self):\n",
    "    return str(self.slots)\n",
    "\n",
    "  def add(self, other_plain):\n",
    "    \"\"\"Method computes the sum of two plaintext objects\n",
    "  Returns:\n",
    "    Plaintext sum of self and other_plain\n",
    "  \"\"\"\n",
    "\n",
    "    result = self.slots + other_plain.slots\n",
    "    result1 = Plaintext(result, self.num_slots)\n",
    "    return result1\n",
    "\n",
    "  def mul(self, other_plain):\n",
    "    \"\"\"Method computes the multiplication of two plaintext objects\n",
    "  Returns:\n",
    "    Plaintext product of self and other_plain\n",
    "  \"\"\"\n",
    "\n",
    "    multresult = self.slots * other_plain.slots\n",
    "    multresult1 = Plaintext(multresult, self.num_slots)\n",
    "    return multresult1\n",
    "\n",
    "  def rotate(self, index):\n",
    "    \"\"\"Method computes the rotation of an object for a specific index\n",
    "  Args:\n",
    "    index: number of slots to rotate by\n",
    "  Returns:\n",
    "    Rotated plaintext object\n",
    "    ex: rotating [1,2,3,4] by 1 returns [2,3,4,1]\n",
    "  \"\"\"\n",
    "\n",
    "    test = np.roll(self.slots,-1* index)\n",
    "    test1 = Plaintext(test, self.num_slots)\n",
    "    return test1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cc6e79c-0dcd-4191-8016-59a8478270a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]\n",
      "  [ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]\n",
      "  [21 22 23 24]\n",
      "  [25 26 27 28]\n",
      "  [29 30 31 32]]\n",
      "\n",
      " [[33 34 35 36]\n",
      "  [37 38 39 40]\n",
      "  [41 42 43 44]\n",
      "  [45 46 47 48]]\n",
      "\n",
      " [[49 50 51 52]\n",
      "  [53 54 55 56]\n",
      "  [57 58 59 60]\n",
      "  [61 62 63 64]]]\n",
      "[[ 1  5  9 13]\n",
      " [17 21 25 29]\n",
      " [33 37 41 45]\n",
      " [49 53 57 61]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'num_input_channels' : 4, # c_i\n",
    "        'input_width' : 4, # w_i\n",
    "        'input_height' : 4, # h_i\n",
    "        'input_gap' : 2, # k_i\n",
    "        'kernel_height': 3, # f_h\n",
    "        'kernel_width': 3, # f_w\n",
    "        'num_output_channels' : 16, # c_o\n",
    "        'output_gap' : 4, # k_o\n",
    "        'output_height' : 2, # h_o\n",
    "        'output_width' : 2, # w_o\n",
    "        't_i' : 1, # t_i: c_i/k_i^2, number of squares to represent all input channels\n",
    "        't_o' : 1, # t_o: c_o/k_o^2, number of squares to represent all input channels\n",
    "        'num_slots' : 2**18\n",
    "}\n",
    "\n",
    "input_image = np.array([[[i * params['num_input_channels'] * params['input_width'] + \\\n",
    "                          j * params['num_input_channels'] + k + 1 for k in range(params['num_input_channels'])] \\\n",
    "                         for j in range(params['input_width'])] for i in range(params['input_height'])])\n",
    "print(input_image) # Should be (input_height, input_width, num_input_channels)\n",
    "input_image_channel_0 = input_image[:, :, 0]\n",
    "print(input_image_channel_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edd06f4a-dfec-491e-a82d-7be2159bd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_pack(A, params):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        A (numpy.ndarray): Input tensor \n",
    "        h_i : Height \n",
    "        w_i : Width \n",
    "        c_i: Number of input channels \n",
    "        params['input_gap']: Input gap\n",
    "        t_i\n",
    "\n",
    "    Returns:\n",
    "        A plaintext object which has a 1-D Numpy array slots.\n",
    "    \"\"\"\n",
    "    # Initialize the output tensor A' with zeros\n",
    "    A_prime = np.zeros((params['input_gap'] * params['input_height'], params['input_gap'] * params['input_width'], params['t_i']))\n",
    "\n",
    "    # Fill the A_prime tensor according to the given formula\n",
    "    for i3 in range(params['input_gap'] * params['input_height']):  # Outer tensor height dimension\n",
    "        for i4 in range(params['input_gap'] * params['input_width']):  # Outer tensor width dimension\n",
    "            for i5 in range(params['t_i']):  # Channel dimension after packing\n",
    "                # Map indices from A to A' based on the input gap\n",
    "                orig_i3 = i3 // params['input_gap']\n",
    "                orig_i4 = i4 // params['input_gap']\n",
    "                orig_i5 = ((params['input_gap'] ** 2) * i5) + params['input_gap'] * (i3 % params['input_gap']) + (i4 % params['input_gap'])\n",
    "\n",
    "                if (\n",
    "                    orig_i3 < A.shape[0]\n",
    "                    and orig_i4 < A.shape[1]\n",
    "                    and orig_i5 < A.shape[2]\n",
    "                    and orig_i5 < params['num_input_channels']\n",
    "                ):\n",
    "                    A_prime[i3, i4, i5] = A[orig_i3, orig_i4, orig_i5]\n",
    "\n",
    "    return Plaintext(A_prime.flatten(), params['num_slots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4056f6a9-7bfb-4a0b-874a-ac55c11cf4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 5. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "p = mult_pack(input_image, params)\n",
    "print(p.slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7823a1f8-a8cd-41bd-98af-b0fba39440d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumSlots(ct_a, m, p):\n",
    "    \"\"\"\n",
    "    SumSlots algorithm implementation using only add, multiply, and rotate.\n",
    "    Args:\n",
    "        ct_a (Plaintext): Input ciphertext.\n",
    "        m (int): Number of added slots\n",
    "        p (int): Gap\n",
    "    \n",
    "    \"\"\"\n",
    "    ct_b = [ct_a]\n",
    "\n",
    "    for j in range(1, int(np.log2(m)) + 1):  # Inclusive loop\n",
    "        rotated = ct_b[j - 1].rotate(2**(j - 1) * p)\n",
    "        ct_b.append(ct_b[j - 1].add(rotated))  \n",
    "\n",
    "    ct_c = ct_b[int(np.log2(m))]\n",
    "\n",
    "    for j in range(0, int(np.log2(m))):  # Exclusive loop\n",
    "        if (m // (2**j)) % 2 == 1:\n",
    "            rotation_distance = (m // (2**(j + 1))) * 2**(j + 1) * p\n",
    "            rotated = ct_b[j].rotate(rotation_distance)\n",
    "            ct_c = ct_c.add(rotated)  \n",
    "\n",
    "    return ct_c #return ciphertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80c217ac-aff9-4c6b-8039-49b818285240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightU(params):\n",
    "    weightU = np.array([[[[i * params['num_input_channels'] * params['kernel_width'] * params['num_output_channels'] + \\\n",
    "                              j * params['num_input_channels'] * params['num_output_channels'] + k * params['num_output_channels'] + \\\n",
    "                              l + 1 \n",
    "                              for l in range(params['num_output_channels'])] \\\n",
    "                              for k in range(params['num_input_channels'])] \\\n",
    "                              for j in range(params['kernel_width'])] \\\n",
    "                              for i in range(params['kernel_height'])])\n",
    "    '''\n",
    "    weightU = np.zeros((params['kernel_height'], params['kernel_width'], params['num_input_channels'], params['num_output_channels']))\n",
    "    count = 1\n",
    "    for i in range(params['kernel_height']):\n",
    "        for j in range(params['kernel_width']):\n",
    "            for k in range(params['num_input_channels']):\n",
    "                for l in range(params['num_output_channels']):\n",
    "                    weightU[i][j][k][l] = count\n",
    "                    count += 1\n",
    "    print(weightU)\n",
    "    '''\n",
    "    return weightU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "217dcff1-9df4-44b6-bc8a-bf438d455546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_weight(U, i1, i2, i, params):\n",
    "    \"\"\"\n",
    "    Creates the multiplexed shifted weight tensor U'\n",
    "    \n",
    "    Args:\n",
    "        U: Original  tensor of shape (fh, fw, ci, co)\n",
    "        i1: Index for filter height dimension\n",
    "        i2: Index for filter width dimension\n",
    "        i: Index for output channel dimension\n",
    "        params: Dictionary containing params ki, hi, wi, ci\n",
    "    \n",
    "    Returns:\n",
    "        Tensor U'(i1,i2,i) of shape (ki*hi, ki*wi, ti)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the output tensor with zeros\n",
    "    result = np.zeros((params['input_gap'] * params['input_height'], params['input_gap'] * params['input_width']), dtype=object)\n",
    "    \n",
    "    # Fill the tensor according to the conditions\n",
    "    for i3 in range(params['input_gap'] * params['input_height']):\n",
    "        for i4 in range(params['input_gap'] * params['input_width']):\n",
    "            for i5 in range(params['t_i']):\n",
    "            # Check all conditions (with i5=0)\n",
    "                cond1 = ((params['input_gap'] ** 2) * i5) + params['input_gap'] * (i3 % params['input_gap']) + \\\n",
    "                            i4 % params['input_gap'] >= params['num_input_channels']\n",
    "                cond2 = (i3 // params['input_gap']) - (params['kernel_height'] - 1) // 2 + i1 not in range(params['input_height'])\n",
    "                cond3 = (i4 // params['input_gap']) - (params['kernel_width'] - 1) // 2 + i2 not in range(params['input_width'])\n",
    "            \n",
    "                if cond1 or cond2 or cond3:\n",
    "                    result[i3, i4] = 0\n",
    "                else:\n",
    "                # Calculate indices for the original tensor U\n",
    "                    u_idx = (i1, i2, ((params['input_gap'] ** 2) * i5) + \\\n",
    "                             params['input_gap'] * (i3 % params['input_gap']) + i4 % params['input_gap'], i)\n",
    "                    result[i3, i4] = U[u_idx]\n",
    "                \n",
    "    return result.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "544bed34-0635-469b-a74a-cd70ef22f3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16]\n",
      "   [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32]\n",
      "   [ 33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48]\n",
      "   [ 49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64]]\n",
      "\n",
      "  [[ 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80]\n",
      "   [ 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96]\n",
      "   [ 97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112]\n",
      "   [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128]]\n",
      "\n",
      "  [[129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144]\n",
      "   [145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160]\n",
      "   [161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176]\n",
      "   [177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192]]]\n",
      "\n",
      "\n",
      " [[[193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208]\n",
      "   [209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224]\n",
      "   [225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240]\n",
      "   [241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256]]\n",
      "\n",
      "  [[257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272]\n",
      "   [273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288]\n",
      "   [289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304]\n",
      "   [305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320]]\n",
      "\n",
      "  [[321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336]\n",
      "   [337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352]\n",
      "   [353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368]\n",
      "   [369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384]]]\n",
      "\n",
      "\n",
      " [[[385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400]\n",
      "   [401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416]\n",
      "   [417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432]\n",
      "   [433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448]]\n",
      "\n",
      "  [[449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464]\n",
      "   [465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480]\n",
      "   [481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496]\n",
      "   [497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512]]\n",
      "\n",
      "  [[513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528]\n",
      "   [529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544]\n",
      "   [545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560]\n",
      "   [561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576]]]]\n",
      "(3, 3, 4, 16)\n",
      "[[  1  65 129]\n",
      " [193 257 321]\n",
      " [385 449 513]]\n"
     ]
    }
   ],
   "source": [
    "U = weightU(params)\n",
    "print(U)\n",
    "print(U.shape)\n",
    "mw = mult_weight(U, 0, 2, 0, params)\n",
    "#print(U.shape)\n",
    "#print(U)\n",
    "count = 0\n",
    "'''\n",
    "for i in range(params['input_gap'] * params['input_height']):\n",
    "    for j in range(params['input_gap'] * params['input_width']):\n",
    "        # print(str(mw[i * params['input_gap'] * params['input_width'] + j])  + \", \", end=\"\")\n",
    "        print(str(mw[count]) + \", \", end=\"\")\n",
    "        count += 1\n",
    "    print()\n",
    "'''\n",
    "test_kernel = U[:, :, 0, 0]\n",
    "print(test_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc1a75b7-01c9-4b34-98fe-157247ce6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_prime(params, i):\n",
    "    S_prime = np.zeros((params['output_gap']*params['output_height'], params['output_gap']*params['output_width'], params['t_o']), dtype=int)\n",
    "\n",
    "    for i3 in range(params['output_gap']*params['output_height']):\n",
    "        for i4 in range(params['output_gap']*params['output_width']):\n",
    "            for i5 in range(params['t_o']):\n",
    "                if ((params['output_gap']**2)*i5) + params['output_gap'] * (i3 % params['output_gap']) + i4 % params['output_gap'] ==i:\n",
    "                    S_prime[i3, i4, i5] = 1\n",
    "                else:\n",
    "                    S_prime[i3, i4, i5] = 0\n",
    "    return(Plaintext(S_prime.flatten(), params['num_slots']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8abb8528-0cc8-4591-84f8-8c62fb03dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "selecting_tensor = S_prime(params, i)\n",
    "print(selecting_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "486cd481-09c4-4dd3-ba32-34b58a74ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multConv(ct_aprime, U, params):\n",
    "    zero_slots = np.zeros(params['num_slots'])\n",
    "    ct_zero = Plaintext(zero_slots, params['num_slots'])\n",
    "    ct_d = ct_zero\n",
    "    ct_prime = {}\n",
    "    for i1 in range(params['kernel_height']):\n",
    "        for i2 in range(params['kernel_width']):\n",
    "            rotation = (params['input_gap'] ** 2) * params['input_width'] * ((i1 - (params['kernel_height'] - 1) // 2)) \\\n",
    "                        + params['input_gap'] * ((i2 - (params['kernel_width'] - 1) // 2 ))\n",
    "            ct_prime[(i1, i2)] = ct_aprime.rotate(rotation)\n",
    "    for i in range(params['num_output_channels']):\n",
    "        ct_b = ct_zero\n",
    "        for i1 in range(params['kernel_height']):\n",
    "            for i2 in range(params['kernel_width']):\n",
    "                weight = mult_weight(U, i1, i2, i, params)\n",
    "                weight_p = Plaintext(weight, params['num_slots'])\n",
    "                ct_b = ct_b.add(ct_prime[(i1, i2)].mul(weight_p))                \n",
    "        ct_c = SumSlots(ct_b, params['input_gap'], 1)\n",
    "        ct_c = SumSlots(ct_c, params['input_gap'], params['input_gap'] * params['input_width'])\n",
    "        ct_c = SumSlots(ct_c, params['t_i'], (params['input_gap'] ** 2) * params['input_height'] * params['input_width'])\n",
    "        rot = -(((i // (params['output_gap'] ** 2)) * (params['output_gap'] ** 2) * params['output_height'] * params['output_width']) + \\\n",
    "                (((i % (params['output_gap']**2)) // params['output_gap']) * params['output_gap'] * params['output_width']) + \\\n",
    "                (i % params['output_gap']))\n",
    "        ct_d = ct_d.add(ct_c.rotate(rot).mul(S_prime(params, i)))\n",
    "    return ct_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94913355-8d5b-4ff9-a114-cf8d6aee4884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 5. ... 0. 0. 0.]\n",
      "[95432.0 95632.0 95832.0 ... 0.0 0.0 0.0]\n",
      "262144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    [ 95432.  95632.  95832.  96032. 190396. 190840. 191284. 191728.  96232.\\n      96432.  96632.  96832. 192172. 192616. 193060. 193504.  97032.  97232.\\n      97432.  97632. 193948. 194392. 194836. 195280.  97832.  98032.  98232.\\n      98432. 195724. 196168. 196612. 197056. 325356. 326232. 327108. 327984.\\n     510522. 512052. 513582. 515112. 328860. 329736. 330612. 331488. 516642.\\n     518172. 519702. 521232. 332364. 333240. 334116. 334992. 522762. 524292.\\n     525822. 527352. 335868. 336744. 337620. 338496. 528882. 530412. 531942.\\n     533472.]\\n '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_aprime = mult_pack(input_image, params)\n",
    "print(ct_aprime)\n",
    "U = weightU(params)\n",
    "ct_d = multConv(ct_aprime, U, params)\n",
    "print(ct_d)\n",
    "print(ct_d.num_slots)\n",
    "\n",
    "'''\n",
    "    [ 95432.  95632.  95832.  96032. 190396. 190840. 191284. 191728.  96232.\n",
    "      96432.  96632.  96832. 192172. 192616. 193060. 193504.  97032.  97232.\n",
    "      97432.  97632. 193948. 194392. 194836. 195280.  97832.  98032.  98232.\n",
    "      98432. 195724. 196168. 196612. 197056. 325356. 326232. 327108. 327984.\n",
    "     510522. 512052. 513582. 515112. 328860. 329736. 330612. 331488. 516642.\n",
    "     518172. 519702. 521232. 332364. 333240. 334116. 334992. 522762. 524292.\n",
    "     525822. 527352. 335868. 336744. 337620. 338496. 528882. 530412. 531942.\n",
    "     533472.]\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39599bcb-d64b-42c2-b96a-f83741996cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroBorder(array):\n",
    "  \"\"\"Method adds a border of zeros around the array\n",
    "  Args:\n",
    "    n: length of the array\n",
    "  Returns:\n",
    "    borderArray: array with a border of zeros\n",
    "  \"\"\"\n",
    "  if array.ndim == 2:\n",
    "      n = array.shape[0]\n",
    "      borderArray = np.zeros((n+2, n+2))\n",
    "      borderArray[1:-1, 1:-1] = array\n",
    "  elif array.ndim == 3:\n",
    "      n, m, c = array.shape\n",
    "      borderArray = np.zeros((n+2, m+2, c))\n",
    "      borderArray[1:-1, 1:-1, :] = array\n",
    "  return borderArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "177a899e-d528-44ff-9e91-74534f31d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputDimensions(image, stride, kernel_height, kernel_width):\n",
    "    borderArray = zeroBorder(image)\n",
    "    padded_height, padded_width, _ = borderArray.shape \n",
    "    outputHeight = ((padded_height - kernel_height) // stride) + 1\n",
    "    outputWidth = ((padded_width - kernel_width) // stride) + 1\n",
    "    return borderArray, outputHeight, outputWidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9d766b6-5523-4aef-bc7f-ab146a5b91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twod_naive_convolution(image, kernel, borderArray, image_height, image_width, kernel_height, kernel_width, stride, outputHeight, outputWidth):\n",
    "  \"\"\"Method computes the convolution of an image and a kernel with only one output channel\n",
    "  Args:\n",
    "    image: image as a 1D array\n",
    "    kernel: kernel as a 1D array\n",
    "    borderArray: image with a border of zeros\n",
    "    outputImage: convoluted image\n",
    "  Returns:\n",
    "    The convoluted image\n",
    "  \"\"\"\n",
    "  \n",
    "  image = image.reshape(image_height, image_width)\n",
    "  kernel = kernel.reshape(kernel_height, kernel_width)\n",
    "\n",
    "  #borderArray = zeroBorder(image)\n",
    "  #padded_height, padded_width = borderArray.shape \n",
    "\n",
    "  #print(f\"The padded image is \\n {borderArray}\")\n",
    "  #outputHeight = ((padded_height - kernel_height) // stride) + 1\n",
    "  #outputWidth = ((padded_width - kernel_width) // stride) + 1\n",
    "  output_Image = np.zeros((outputHeight, outputWidth))\n",
    "    \n",
    "  for i in range(outputHeight):\n",
    "      for j in range(outputWidth):\n",
    "          start_i = i * stride\n",
    "          start_j = j * stride\n",
    "          matrix = borderArray[start_i : start_i + kernel_height, start_j : start_j + kernel_width]\n",
    "          mult = np.multiply(matrix, kernel)\n",
    "          add = np.sum(mult)\n",
    "          output_Image[i, j] = add\n",
    "  return output_Image\n",
    "\n",
    "def threed_naive_convolution2(image, kernel, image_height, image_width, kernel_height, kernel_width,\n",
    "                              stride, num_input_channels, num_output_channels):\n",
    "    \"\"\"Method computes the convolution of an image and a kernel with only one output channel\n",
    "    Args:\n",
    "    image: image with dimensions (image_height, image_width, num_input_channels)\n",
    "    kernel: kernel with dimensions (kernel_height, kernel_width. num_input_channels, num_output_channels)\n",
    "    Returns:\n",
    "    The convoluted image\n",
    "    \"\"\"\n",
    "   \n",
    "    \"\"\"\n",
    "    1 2 3 4\n",
    "    5 6 7 8 \n",
    "    9 10 11 12\n",
    "    13 14 15 16\n",
    "\n",
    "    stride 2 --> (0, 0) goes to (0, 0)\n",
    "    (0, 2) goes to (0, 1)\n",
    "    (2, 0) goes to (1, 0)\n",
    "    (2, 2) goes to (1, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #print(f\"The padded image is \\n {borderArray}\")\n",
    "    output_height = int(np.ceil(image_height / stride))\n",
    "    output_width = int(np.ceil(image_width / stride))\n",
    "    output_image = np.zeros((output_height, output_width, num_output_channels))\n",
    "\n",
    "    for k in range(num_output_channels):\n",
    "        for l in range(num_input_channels):\n",
    "            for i in range(output_height):          \n",
    "                for j in range(output_width):\n",
    "                    for a in range(kernel_height):\n",
    "                        for b in range(kernel_width):\n",
    "                            start_i = stride * i - kernel_height // 2\n",
    "                            start_j = stride * j - kernel_width // 2\n",
    "                            if 0 <= start_i + a < image_height and 0 <= start_j + b < image_width:\n",
    "                                output_image[i][j][k] += image[start_i + a][start_j + b][l] * kernel[a][b][l][k]\n",
    "                                \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43271b3c-95c5-4134-9efd-c80201b3f734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 22576.]\n",
      "  [ 45484.]]\n",
      "\n",
      " [[ 78552.]\n",
      "  [123162.]]]\n"
     ]
    }
   ],
   "source": [
    "num_input = 2\n",
    "num_output = 1\n",
    "image_height = 4\n",
    "image_width = 4\n",
    "kernel_width = 3\n",
    "kernel_height = 3\n",
    "stride = 2\n",
    "image = np.array([1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16])\n",
    "image = image.reshape((image_height, image_width, num_input))\n",
    "kernel = np.array([1, -1, 2, -2, 3, -3, 4, -4, 5, -5, 6, -6, 7, -7, 8, -8, 9, -9])\n",
    "kernel = kernel.reshape((kernel_height, kernel_width, num_input, num_output))\n",
    "\n",
    "threed = threed_naive_convolution2(image, kernel, image_height, image_width, kernel_height, kernel_width, stride, num_input, num_output)\n",
    "test1 = threed_naive_convolution2(input_image[:, :, 1].reshape((params['input_height'], params['input_width'], 1)), U[:, :, 1, 0].reshape((params['kernel_height'], params['kernel_width'], 1, 1)), params['input_height'], params['input_width'], params['kernel_height'], params['kernel_width'], params['input_gap'], 1, 1)\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fac406d-4964-403b-8343-5fd1f40f810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[20268.0 22576.0 33166.0 36628.0 41638.0 45484.0 27724.0 30288.0 25012.0\\n 27576.0 40282.0 44128.0 49522.0 53752.0 32980.0 35800.0 45618.0 49272.0\\n 68541.0 74022.0 77793.0 83850.0 49122.0 53160.0 53118.0 57156.0 79791.0\\n 85848.0 90195.0 96828.0 57390.0 61812.0 73362.0 78552.0 105549.0 113334.0\\n 114801.0 123162.0 70722.0 76296.0 83934.0 89508.0 121407.0 129768.0\\n 131811.0 140748.0 82062.0 88020.0 36524.0 40112.0 49102.0 54484.0 52966.0\\n 58732.0 29644.0 33488.0 43828.0 47672.0 60058.0 65824.0 64690.0 70840.0\\n 37460.0 41560.0]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''[20268.0 22576.0 33166.0 36628.0 41638.0 45484.0 27724.0 30288.0 25012.0\n",
    " 27576.0 40282.0 44128.0 49522.0 53752.0 32980.0 35800.0 45618.0 49272.0\n",
    " 68541.0 74022.0 77793.0 83850.0 49122.0 53160.0 53118.0 57156.0 79791.0\n",
    " 85848.0 90195.0 96828.0 57390.0 61812.0 73362.0 78552.0 105549.0 113334.0\n",
    " 114801.0 123162.0 70722.0 76296.0 83934.0 89508.0 121407.0 129768.0\n",
    " 131811.0 140748.0 82062.0 88020.0 36524.0 40112.0 49102.0 54484.0 52966.0\n",
    " 58732.0 29644.0 33488.0 43828.0 47672.0 60058.0 65824.0 64690.0 70840.0\n",
    " 37460.0 41560.0]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b27c16c7-bce5-43fd-8b7a-f0569fa85f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_input = 2\\nnum_output = 1\\nkernel_height = 3\\nkernel_width = 3\\ninput_height = 3\\ninput_width = 3\\nstride = 2\\n\\nweightU = np.array([[[[i * num_input * kernel_width * num_output +                               j * num_input * num_output + k * num_output +                               l + 1 \\n                              for l in range(num_output)]                               for k in range(num_input)]                               for j in range(kernel_width)]                               for i in range(kernel_height)])\\ninput_image = np.array([[[i * num_input * input_width +                           j * num_input + k + 1 for k in range(num_input)]                          for j in range(input_width)] for i in range(input_height)])\\nprint(input_image)\\nprint(weightU)\\ntest = threed_naive_convolution(input_image, weightU, input_height, input_width, num_input, num_output, kernel_height, kernel_width, stride)\\nprint(test)\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "num_input = 2\n",
    "num_output = 1\n",
    "kernel_height = 3\n",
    "kernel_width = 3\n",
    "input_height = 3\n",
    "input_width = 3\n",
    "stride = 2\n",
    "\n",
    "weightU = np.array([[[[i * num_input * kernel_width * num_output + \\\n",
    "                              j * num_input * num_output + k * num_output + \\\n",
    "                              l + 1 \n",
    "                              for l in range(num_output)] \\\n",
    "                              for k in range(num_input)] \\\n",
    "                              for j in range(kernel_width)] \\\n",
    "                              for i in range(kernel_height)])\n",
    "input_image = np.array([[[i * num_input * input_width + \\\n",
    "                          j * num_input + k + 1 for k in range(num_input)] \\\n",
    "                         for j in range(input_width)] for i in range(input_height)])\n",
    "print(input_image)\n",
    "print(weightU)\n",
    "test = threed_naive_convolution(input_image, weightU, input_height, input_width, num_input, num_output, kernel_height, kernel_width, stride)\n",
    "print(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca034fb1-e980-4438-9204-a04840a268d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the above output matches multPack(C)\n",
    "# C = 3d-conv(input_image, U, params) with stride 2\n",
    "# Implement 3d-conv with stride parameter and test with s = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc7b4595-21fa-4334-b40b-712f3b8f5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputParams = {\n",
    "        'num_input_channels' : 16, # c_i\n",
    "        'input_width' : 2, # w_i\n",
    "        'input_height' : 2, # h_i\n",
    "        'input_gap' : 4, # k_i\n",
    "        'kernel_height': 3, # f_h\n",
    "        'kernel_width': 3, # f_w\n",
    "        'num_output_channels' : 16, # c_o\n",
    "        'output_gap' : 4, # k_o\n",
    "        'output_height' : 2, # h_o\n",
    "        'output_width' : 2, # w_o\n",
    "        't_i' : 1, # t_i: c_i/k_i^2, number of squares to represent all input channels\n",
    "        't_o' : 1, # t_o: c_o/k_o^2, number of squares to represent all input channels\n",
    "        'num_slots' : 2**18\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2edcafa-3cbc-44bb-bb16-e552f965d0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 4, 16)\n",
      "(4, 4, 4)\n",
      "[[[ 95432.  95632.  95832.  96032.  96232.  96432.  96632.  96832.\n",
      "    97032.  97232.  97432.  97632.  97832.  98032.  98232.  98432.]\n",
      "  [190396. 190840. 191284. 191728. 192172. 192616. 193060. 193504.\n",
      "   193948. 194392. 194836. 195280. 195724. 196168. 196612. 197056.]]\n",
      "\n",
      " [[325356. 326232. 327108. 327984. 328860. 329736. 330612. 331488.\n",
      "   332364. 333240. 334116. 334992. 335868. 336744. 337620. 338496.]\n",
      "  [510522. 512052. 513582. 515112. 516642. 518172. 519702. 521232.\n",
      "   522762. 524292. 525822. 527352. 528882. 530412. 531942. 533472.]]]\n",
      "[95432. 95632. 95832. ...     0.     0.     0.]\n"
     ]
    }
   ],
   "source": [
    "print(U.shape)\n",
    "print(input_image.shape)\n",
    "C = threed_naive_convolution2(input_image, U, params['input_height'], params['input_width'], params['kernel_height'], params['kernel_width'], params['input_gap'], params['num_input_channels'], params['num_output_channels'],)\n",
    "print(C)\n",
    "print((mult_pack(C, outputParams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5afbb60c-d311-46c8-94da-6e52ea852288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput_gap = stride * input_gap\\n\\n**include stride\\n\\nlayer 1:\\noutput_channels = 16\\ninput_channels = 1\\ninput_height = 256\\ninput_width = 256\\nkernel_height = 5\\nkernel_width = 5\\nt_i = 1\\nt_o = 4\\n\\nresult:\\noutput_height = 128\\noutput_width = 128\\n\\nlayer 2:\\ninput_channels = 16\\noutput_channels = 32\\nkernel_height = 3\\nkernel_width = 3\\nt_i = 4\\nt_o = 8\\n\\n\\nlayer 3:\\ninput_gap = 1\\noutput_gap = 1\\ninput_channels = 32\\noutput_channels = 64\\nkernel_height = 3\\nkernel_width = 3\\nt_i = 8\\nt_o = 16\\n\\nlayer 4:\\ninput_gap = 1\\noutput_gap = 1\\ninput_channels = 64\\noutput_channels = 128\\nkernel_height = 3\\nkernel_width = 3\\nt_i = 16\\nt_o = 32\\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "output_gap = stride * input_gap\n",
    "\n",
    "**include stride\n",
    "\n",
    "layer 1:\n",
    "output_channels = 16\n",
    "input_channels = 1\n",
    "input_height = 256\n",
    "input_width = 256\n",
    "kernel_height = 5\n",
    "kernel_width = 5\n",
    "t_i = 1\n",
    "t_o = 4\n",
    "\n",
    "result:\n",
    "output_height = 128\n",
    "output_width = 128\n",
    "\n",
    "layer 2:\n",
    "input_channels = 16\n",
    "output_channels = 32\n",
    "kernel_height = 3\n",
    "kernel_width = 3\n",
    "t_i = 4\n",
    "t_o = 8\n",
    "\n",
    "\n",
    "layer 3:\n",
    "input_gap = 1\n",
    "output_gap = 1\n",
    "input_channels = 32\n",
    "output_channels = 64\n",
    "kernel_height = 3\n",
    "kernel_width = 3\n",
    "t_i = 8\n",
    "t_o = 16\n",
    "\n",
    "layer 4:\n",
    "input_gap = 1\n",
    "output_gap = 1\n",
    "input_channels = 64\n",
    "output_channels = 128\n",
    "kernel_height = 3\n",
    "kernel_width = 3\n",
    "t_i = 16\n",
    "t_o = 32\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71deb81-f5a7-4fac-ac17-4505d938ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_layer_one = {\n",
    "        'num_input_channels' : 1, # c_i\n",
    "        'input_width' : 256, # w_i\n",
    "        'input_height' : 256, # h_i\n",
    "        'input_gap' : 1, # k_i\n",
    "        'kernel_height': 5, # f_h\n",
    "        'kernel_width': 5, # f_w\n",
    "        'num_output_channels' : 16, # c_o\n",
    "        'output_gap' : 2, # k_o\n",
    "        'stride' : 2,\n",
    "        'output_height' : 128, # h_o\n",
    "        'output_width' : 128, # w_o\n",
    "        't_i' : 1, # t_i: c_i/k_i^2, number of squares to represent all input channels\n",
    "        't_o' : 4, # t_o: c_o/k_o^2, number of squares to represent all input channels\n",
    "        'num_slots' : 2**18\n",
    "}\n",
    "input_image_one = np.array([[[i * params_layer_one['num_input_channels'] * params_layer_one['input_width'] + \\\n",
    "                          j * params_layer_one['num_input_channels'] + k + 1 for k in range(params_layer_one['num_input_channels'])] \\\n",
    "                         for j in range(params_layer_one['input_width'])] for i in range(params_layer_one['input_height'])])\n",
    "\n",
    "\n",
    "ct_aprime_one = mult_pack(input_image_one, params_layer_one)\n",
    "U_one = weightU(params_layer_one)\n",
    "ct_d_one = multConv(ct_aprime_one, U_one, params_layer_one)\n",
    "print(ct_d_one)\n",
    "\n",
    "C_one = threed_naive_convolution2(input_image_one, U_one, params_layer_one['input_height'], params_layer_one['input_width'], params_layer_one['kernel_height'], params_layer_one['kernel_width'], params_layer_one['stride'], params_layer_one['num_input_channels'], params_layer_one['num_output_channels'])\n",
    "#print(C_one)\n",
    "print((mult_pack(C_one, params_layer_one)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6d1cd6c-c01b-47ca-a84a-2a409da48580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144\n",
      "262144\n",
      "[794034.0 0.0 0.0 0.0 1273880.0 0.0 0.0 0.0 1290455.0 0.0]\n",
      "[ 794034. 1265885. 1274075. 1282265. 1290455. 1298645. 1306835. 1315025.\n",
      " 1323215. 1331405.]\n"
     ]
    }
   ],
   "source": [
    "print(ct_d_one.num_slots)\n",
    "mult_pack_C_one = mult_pack(C_one, params_layer_one)\n",
    "print(mult_pack_C_one.num_slots)\n",
    "\n",
    "print(ct_d_one.slots[: 10])\n",
    "print(mult_pack_C_one.slots[: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310e314-7752-4aa2-88f9-3c66a9a700d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144\n",
      "(3, 3, 16, 32)\n"
     ]
    }
   ],
   "source": [
    "params_layer_two = {\n",
    "        'num_input_channels' : 16, # c_i\n",
    "        'input_width' : 64, # w_i\n",
    "        'input_height' : 64, # h_i\n",
    "        'input_gap' : 2, # k_i\n",
    "        'kernel_height': 3, # f_h\n",
    "        'kernel_width': 3, # f_w\n",
    "        'num_output_channels' : 32, # c_o\n",
    "        'output_gap' : 4, # k_o\n",
    "        'output_height' : 32, # h_o\n",
    "        'output_width' : 32, # w_o\n",
    "        't_i' : 4, # t_i: c_i/k_i^2, number of squares to represent all input channels\n",
    "        't_o' : 8, # t_o: c_o/k_o^2, number of squares to represent all input channels\n",
    "        'num_slots' : 2**18\n",
    "}\n",
    "input_image_two = np.array([[[i * params_layer_two['num_input_channels'] * params_layer_two['input_width'] + \\\n",
    "                          j * params_layer_two['num_input_channels'] + k + 1 for k in range(params_layer_two['num_input_channels'])] \\\n",
    "                         for j in range(params_layer_two['input_width'])] for i in range(params_layer_two['input_height'])])\n",
    "\n",
    "\n",
    "ct_aprime_two = mult_pack(input_image_two, params_layer_two)\n",
    "print(ct_aprime_two.num_slots)\n",
    "U_two = weightU(params_layer_two)\n",
    "print(U_two.shape)\n",
    "ct_d_two = multConv(ct_aprime_two, U_two, params_layer_two)\n",
    "print(ct_d_two)\n",
    "\n",
    "C_two = threed_naive_convolution2(input_image_two, U_two, params_layer_two['input_height'], params_layer_two['input_width'], params_layer_two['kernel_height'], params_layer_two['kernel_width'], params_layer_two['input_gap'], params_layer_two['num_input_channels'], params_layer_two['num_output_channels'])\n",
    "#print(C_two.shape)\n",
    "print((mult_pack(C_two, params_layer_two)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4faef439-1098-4490-852a-ea71477a5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      "[5.93899584e+08 5.94490432e+08 0.00000000e+00 ... 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "params_layer_three = {\n",
    "        'num_input_channels' : 32, # c_i\n",
    "        'input_width' : 16, # w_i\n",
    "        'input_height' : 16, # h_i\n",
    "        'input_gap' : 4, # k_i\n",
    "        'kernel_height': 3, # f_h\n",
    "        'kernel_width': 3, # f_w\n",
    "        'num_output_channels' : 64, # c_o\n",
    "        'output_gap' : 4, # k_o\n",
    "        'output_height' : 16, # h_o\n",
    "        'output_width' : 16, # w_o\n",
    "        't_i' : 8, # t_i: c_i/k_i^2, number of squares to represent all input channels\n",
    "        't_o' : 16, # t_o: c_o/k_o^2, number of squares to represent all input channels\n",
    "        'num_slots' : 2**18\n",
    "}\n",
    "input_image_three = np.array([[[i * params_layer_three['num_input_channels'] * params_layer_three['input_width'] + \\\n",
    "                          j * params_layer_three['num_input_channels'] + k + 1 for k in range(params_layer_three['num_input_channels'])] \\\n",
    "                         for j in range(params_layer_three['input_width'])] for i in range(params_layer_three['input_height'])])\n",
    "\n",
    "\n",
    "ct_aprime_three = mult_pack(input_image_three, params_layer_three)\n",
    "U_three = weightU(params_layer_three)\n",
    "ct_d_three = multConv(ct_aprime_three, U_three, params_layer_three)\n",
    "print(ct_d_three)\n",
    "\n",
    "C_three = threed_naive_convolution2(input_image_three, U_three, params_layer_three['input_height'], params_layer_three['input_width'], params_layer_three['kernel_height'], params_layer_three['kernel_width'], params_layer_three['input_gap'], params_layer_three['num_input_channels'], params_layer_three['num_output_channels'])\n",
    "print((mult_pack(C_three, params_layer_three)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "520f78e7-b479-40c0-b732-591ddcf1bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25155440.0 30271992.0 0.0 ... 0.0 0.0 0.0]\n",
      "[1.37399328e+08 1.37534624e+08 1.37669920e+08 ... 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "params_layer_four = {\n",
    "        'num_input_channels' : 32, # c_i\n",
    "        'input_width' : 16, # w_i\n",
    "        'input_height' : 16, # h_i\n",
    "        'input_gap' : 4, # k_i\n",
    "        'kernel_height': 3, # f_h\n",
    "        'kernel_width': 3, # f_w\n",
    "        'num_output_channels' : 64, # c_o\n",
    "        'output_gap' : 4, # k_o\n",
    "        'output_height' : 16, # h_o\n",
    "        'output_width' : 16, # w_o\n",
    "        't_i' : 8, # t_i: c_i/k_i^2, number of squares to represent all input channels\n",
    "        't_o' : 16, # t_o: c_o/k_o^2, number of squares to represent all input channels\n",
    "        'num_slots' : 2**18\n",
    "}\n",
    "input_image_two = np.array([[[i * params_layer_two['num_input_channels'] * params_layer_two['input_width'] + \\\n",
    "                          j * params_layer_two['num_input_channels'] + k + 1 for k in range(params_layer_two['num_input_channels'])] \\\n",
    "                         for j in range(params_layer_two['input_width'])] for i in range(params_layer_two['input_height'])])\n",
    "\n",
    "\n",
    "ct_aprime_two = mult_pack(input_image_two, params_layer_two)\n",
    "U_two = weightU(params_layer_two)\n",
    "ct_d_two = multConv(ct_aprime_two, U_two, params_layer_two)\n",
    "print(ct_d_two)\n",
    "\n",
    "C_two = threed_naive_convolution2(input_image_two, U_two, params_layer_two['input_height'], params_layer_two['input_width'], params_layer_two['kernel_height'], params_layer_two['kernel_width'], params_layer_two['input_gap'], params_layer_two['num_input_channels'], params_layer_two['num_output_channels'])\n",
    "print((mult_pack(C_two, params_layer_two)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4894b3-a90e-4d10-89c3-a800ab39dd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
